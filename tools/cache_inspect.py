#!/usr/bin/env python3
"""Interactive cache visualiser for header_net preprocessing."""

from __future__ import annotations

import argparse
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence, Tuple

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

HEADER_NET_ROOT = Path(__file__).resolve().parents[1]
if str(HEADER_NET_ROOT) not in sys.path:
    sys.path.append(str(HEADER_NET_ROOT))

from configs import header_default as cfg
from cache.create_cache_header import VideoSource, discover_video_sources
from utils.detections import load_ball_det_dict, make_video_key


@dataclass
class SampleSelection:
    video_id: str
    half: int
    frame: int
    label: int
    cache_path: Path


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Visualise cached samples alongside original detections")
    parser.add_argument(
        "--video-id",
        required=True,
        help="Match identifier (e.g. 'TeamA-TeamB'). Append '_half1' to target a specific half or supply --half.",
    )
    parser.add_argument(
        "--half",
        type=int,
        choices=[1, 2],
        help="Match half (1 or 2). Required when --video-id does not already include '_halfX'.",
    )
    parser.add_argument(
        "--train-index",
        type=str,
        default=str(cfg.CACHE_PATH / "cache_header" / "train_cache_header.csv"),
        help="Path to train_cache_header.csv produced by create_cache_header.py",
    )
    parser.add_argument(
        "--ball-det-dict",
        type=str,
        default=str(cfg.BALL_DET_DICT_PATH),
        help="Path to ball_det_dict.npy generated by build_ball_det_dict.py",
    )
    parser.add_argument(
        "--dataset-path",
        type=str,
        default=str(cfg.DATASET_PATH),
        help="Root path to DeepImpact dataset containing SoccerNet videos",
    )
    parser.add_argument(
        "--pos-index",
        type=int,
        default=0,
        help="Index of positive sample to visualise for the chosen video (0-based)",
    )
    parser.add_argument(
        "--neg-index",
        type=int,
        default=0,
        help="Index of negative sample to visualise for the chosen video (0-based)",
    )
    parser.add_argument(
        "--auto",
        action="store_true",
        help="Automatically step through frames without waiting for user input",
    )
    parser.add_argument(
        "--delay",
        type=float,
        default=0.6,
        help="Delay in seconds between frames when --auto is enabled",
    )
    return parser.parse_args()


def resolve_video_key(raw_video_id: str, half: Optional[int]) -> Tuple[str, int, str]:
    """Return (video_id, half, key) irrespective of how the user specified the match."""
    if raw_video_id.endswith("_half1"):
        return raw_video_id[:-6], 1, raw_video_id
    if raw_video_id.endswith("_half2"):
        return raw_video_id[:-6], 2, raw_video_id
    if half is None:
        raise ValueError("Please supply --half when --video-id does not include '_halfX'")
    key = make_video_key(raw_video_id, half)
    return raw_video_id, half, key


def load_samples(csv_path: Path) -> pd.DataFrame:
    df = pd.read_csv(csv_path)
    if "path" not in df.columns:
        raise ValueError(f"Expected 'path' column in {csv_path}")
    df["cache_path"] = df["path"].apply(lambda p: Path(p))
    df["cache_file"] = df["cache_path"].apply(lambda p: p.parent / f"{p.name}_s.npy")
    return df


def choose_sample(df: pd.DataFrame, video_id: str, half: int, label: int, index: int) -> Optional[SampleSelection]:
    subset = df[(df["video_id"] == video_id) & (df["half"] == half) & (df["label"] == label)]
    if subset.empty:
        return None
    subset = subset.sort_values("frame").reset_index(drop=True)
    index = max(0, min(index, len(subset) - 1))
    row = subset.iloc[index]
    cache_file = Path(row["cache_file"])
    if not cache_file.exists():
        raise FileNotFoundError(f"Cache file not found: {cache_file}")
    return SampleSelection(
        video_id=video_id,
        half=int(half),
        frame=int(row["frame"]),
        label=int(row["label"]),
        cache_path=cache_file,
    )


def load_color_frames(video_path: Path, indices: Sequence[int]) -> Dict[int, np.ndarray]:
    unique = sorted(set(idx for idx in indices if idx >= 0))
    frames: Dict[int, np.ndarray] = {}
    if not unique:
        return frames

    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise RuntimeError(f"Unable to open video {video_path}")

    current_pos = 0
    for target in unique:
        if target < current_pos:
            cap.set(cv2.CAP_PROP_POS_FRAMES, target)
            current_pos = target
        while current_pos <= target:
            ret, frame = cap.read()
            if not ret:
                break
            if current_pos == target:
                frames[target] = frame.copy()
                break
            current_pos += 1
        current_pos = target + 1
    cap.release()
    return frames


def prepare_detection_sequence(
    sample: SampleSelection,
    cache_array: np.ndarray,
    window: Sequence[int],
    det_map: Dict[int, Dict[int, Dict[str, float]]],
    video_source: VideoSource,
) -> Tuple[List[np.ndarray], List[np.ndarray], List[Optional[Dict[str, float]]], List[int], List[int]]:
    """Return original frames with overlays, cached patches, detection metadata, frame indices, and offsets used."""
    target_frames = [sample.frame + offset for offset in window]
    original_frames = load_color_frames(video_source.path, target_frames)
    overlays: List[np.ndarray] = []
    patches: List[np.ndarray] = []
    detections: List[Optional[Dict[str, float]]] = []
    valid_indices: List[int] = []
    offsets_used: List[int] = []

    for idx, frame_id in enumerate(target_frames):
        base_frame = original_frames.get(frame_id)
        if base_frame is None:
            continue

        frame_disp = base_frame.copy()
        det_entry = det_map.get(frame_id, {})
        det: Optional[Dict[str, float]] = None
        if det_entry:
            det = max(det_entry.values(), key=lambda rec: rec.get("confidence", 0.0))
            x, y, w, h = det.get("box", [0, 0, 0, 0])
            pt1 = (int(round(x)), int(round(y)))
            pt2 = (int(round(x + w)), int(round(y + h)))
            cv2.rectangle(frame_disp, pt1, pt2, (0, 255, 0), 2)
            cv2.putText(
                frame_disp,
                f"{det.get('confidence', 0.0):.2f}",
                (pt1[0], max(0, pt1[1] - 10)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 0),
                2,
            )
        else:
            cv2.putText(
                frame_disp,
                "No detection",
                (20, 40),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                (0, 0, 255),
                2,
            )

        overlays.append(frame_disp)
        if idx < cache_array.shape[0]:
            patches.append(cache_array[idx].astype(np.uint8))
        else:
            patches.append(np.zeros_like(cache_array[0], dtype=np.uint8))
        detections.append(det)
        valid_indices.append(frame_id)
        offsets_used.append(window[idx])

    return overlays, patches, detections, valid_indices, offsets_used


def display_sequence(
    title: str,
    overlays: List[np.ndarray],
    patches: List[np.ndarray],
    frame_indices: List[int],
    offsets: Sequence[int],
    auto: bool,
    delay: float,
) -> None:
    if not overlays:
        print(f"No frames available for sequence '{title}'")
        return

    plt.ion()
    for idx, (frame, patch, frame_id) in enumerate(zip(overlays, patches, frame_indices)):
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        fig, axes = plt.subplots(1, 2, figsize=(12, 6))
        axes[0].imshow(frame_rgb)
        axes[0].set_title(f"{title} | Frame {frame_id} (offset {offsets[idx]})")
        axes[0].axis("off")

        axes[1].imshow(patch)
        axes[1].set_title("Cached crop")
        axes[1].axis("off")

        plt.tight_layout()
        plt.show(block=False)

        if auto:
            plt.pause(delay)
        else:
            user = input("Press Enter for next frame (q to stop sequence): ").strip().lower()
            if user == "q":
                plt.close(fig)
                break
        plt.close(fig)
    plt.ioff()


def main() -> None:
    args = parse_args()
    csv_path = Path(args.train_index)
    ball_dict_path = Path(args.ball_det_dict)
    dataset_path = Path(args.dataset_path)

    video_id, half, video_key = resolve_video_key(args.video_id, args.half)
    df = load_samples(csv_path)

    pos_sample = choose_sample(df, video_id, half, label=1, index=args.pos_index)
    neg_sample = choose_sample(df, video_id, half, label=0, index=args.neg_index)

    if pos_sample is None and neg_sample is None:
        raise SystemExit(f"No samples found for {video_id} half {half} in {csv_path}")

    detections = load_ball_det_dict(ball_dict_path)
    sources = discover_video_sources(dataset_path, matches=[video_id])
    video_source = sources.get(video_key)
    if video_source is None:
        raise SystemExit(f"Could not locate video source for {video_key}")

    window = list(cfg.WINDOW_SIZE)

    def process_sample(sample: SampleSelection, name: str) -> None:
        cache_array = np.load(sample.cache_path).astype(np.uint8)
        if cache_array.ndim != 4:
            raise ValueError(f"Unexpected cache shape {cache_array.shape} in {sample.cache_path}")
        det_map = detections.get(make_video_key(sample.video_id, sample.half), {})
        overlays, patches, _, frame_indices, offsets_used = prepare_detection_sequence(
            sample,
            cache_array,
            window,
            det_map,
            video_source,
        )
        display_sequence(
            title=f"{name} sample (frame {sample.frame}, label {sample.label})",
            overlays=overlays,
            patches=patches,
            frame_indices=frame_indices,
            offsets=offsets_used,
            auto=args.auto,
            delay=args.delay,
        )

    if pos_sample is not None:
        print(
            f"Visualising positive sample for {video_key}: frame {pos_sample.frame} "
            f"(index {args.pos_index})"
        )
        process_sample(pos_sample, "Positive")
    else:
        print(f"No positive samples available for {video_key}")

    if neg_sample is not None:
        print(
            f"Visualising negative sample for {video_key}: frame {neg_sample.frame} "
            f"(index {args.neg_index})"
        )
        process_sample(neg_sample, "Negative")
    else:
        print(f"No negative samples available for {video_key}")


if __name__ == "__main__":
    main()
